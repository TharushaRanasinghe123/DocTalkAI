<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>DocTalk A1 - Real-Time Transcription Test</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }
        .container {
            background: white;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        button {
            padding: 10px 15px;
            background-color: #4CAF50;
            color: white;
            border: none;
            border-radius: 4px;
            cursor: pointer;
            margin-right: 10px;
            font-size: 16px;
        }
        button:disabled {
            background-color: #cccccc;
            cursor: not-allowed;
        }
        button.stop {
            background-color: #f44336;
        }
        .transcript {
            margin-top: 20px;
            padding: 15px;
            border: 1px solid #ddd;
            border-radius: 4px;
            min-height: 150px;
            background-color: #f9f9f9;
            line-height: 1.6;
        }
        .status-container {
            margin: 15px 0;
            padding: 12px;
            border-radius: 6px;
            background-color: #f8f9fa;
            border: 1px solid #e9ecef;
        }
        .status-item {
            margin: 5px 0;
            padding: 5px;
        }
        .status-connected {
            color: #28a745;
            font-weight: bold;
        }
        .status-disconnected {
            color: #dc3545;
            font-weight: bold;
        }
        .status-waiting {
            color: #ffc107;
            font-weight: bold;
        }
        .interim {
            color: #666;
            font-style: italic;
            opacity: 0.8;
        }
        .final {
            color: #000;
            font-weight: normal;
        }
        .debug-info {
            margin-top: 15px;
            padding: 10px;
            background-color: #e9ecef;
            border-radius: 4px;
            font-family: monospace;
            font-size: 12px;
            max-height: 100px;
            overflow-y: auto;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>DocTalk A1 - Real-Time Transcription Test</h1>
        <p>Click "Start Recording" and speak into your microphone. The transcript will appear below.</p>
        
        <div class="status-container">
            <div class="status-item">
                <strong>Backend Server: </strong>
                <span id="backendStatus" class="status-disconnected">Checking...</span>
            </div>
            <div class="status-item">
                <strong>WebSocket: </strong>
                <span id="websocketStatus" class="status-disconnected">Disconnected</span>
            </div>
            <div class="status-item">
                <strong>Microphone: </strong>
                <span id="microphoneStatus" class="status-disconnected">Not active</span>
            </div>
        </div>
        
        <div>
            <button id="startButton">Start Recording</button>
            <button id="stopButton" class="stop" disabled>Stop Recording</button>
            <button id="clearButton">Clear Transcript</button>
        </div>
        
        <div class="transcript">
            <p><strong>Live Transcript:</strong></p>
            <div id="transcriptContainer">
                <span id="interimText" class="interim"></span>
                <div id="finalText" class="final"></div>
            </div>
        </div>
        
        <div class="debug-info">
            <strong>Debug Log:</strong>
            <div id="debugLog"></div>
        </div>
    </div>

    <script>
        const startButton = document.getElementById('startButton');
        const stopButton = document.getElementById('stopButton');
        const clearButton = document.getElementById('clearButton');
        const interimText = document.getElementById('interimText');
        const finalText = document.getElementById('finalText');
        const backendStatus = document.getElementById('backendStatus');
        const websocketStatus = document.getElementById('websocketStatus');
        const microphoneStatus = document.getElementById('microphoneStatus');
        const debugLog = document.getElementById('debugLog');
        
        let mediaRecorder;
        let audioContext;
        let socket;
        let audioStream;
        let isRecording = false;
        let currentInterim = '';
        
        // Add message to debug log
        function logDebug(message) {
            const timestamp = new Date().toLocaleTimeString();
            debugLog.innerHTML += `[${timestamp}] ${message}<br>`;
            debugLog.scrollTop = debugLog.scrollHeight;
        }
        
        // Update status display
        function updateStatus(element, message, status) {
            element.textContent = message;
            element.className = `status-${status}`;
        }
        
        // Clear transcript
        clearButton.addEventListener('click', () => {
            interimText.textContent = '';
            finalText.innerHTML = '';
            currentInterim = '';
            logDebug('Transcript cleared');
        });
        
        // Test backend connection
        async function testBackendConnection() {
            try {
                logDebug('Testing backend connection...');
                const response = await fetch('http://localhost:8001/health');
                
                if (response.ok) {
                    updateStatus(backendStatus, 'Connected (Port 8001)', 'connected');
                    logDebug('âœ… Backend server is running');
                    return true;
                }
            } catch (error) {
                updateStatus(backendStatus, 'Not connected', 'disconnected');
                logDebug('âŒ Cannot connect to backend: ' + error.message);
            }
            return false;
        }
        
        // Initialize connection test
        window.addEventListener('load', async () => {
            logDebug('Page loaded');
            await testBackendConnection();
        });
        
        startButton.addEventListener('click', startRecording);
        stopButton.addEventListener('click', stopRecording);
        
        async function startRecording() {
            if (isRecording) return;

            interimText.textContent = '';
            finalText.innerHTML = '';
            currentInterim = '';
            
            // Check backend connection first
            if (!await testBackendConnection()) {
                alert('Cannot connect to backend server. Please make sure it\'s running on port 8001.');
                return;
            }
            
            try {
                logDebug('Requesting microphone access...');
                updateStatus(microphoneStatus, 'Requesting access...', 'waiting');
                
                // Get microphone access with proper settings for Deepgram
                audioStream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        sampleRate: 16000,
                        channelCount: 1,
                        echoCancellation: true,
                        noiseSuppression: true
                    } 
                });
                
                updateStatus(microphoneStatus, 'Active', 'connected');
                logDebug('âœ… Microphone access granted');
                
                // Set up WebSocket connection
                const wsUrl = "ws://localhost:8001/ws/transcribe";
                logDebug(`Connecting to WebSocket: ${wsUrl}`);
                updateStatus(websocketStatus, 'Connecting...', 'waiting');
                
                socket = new WebSocket(wsUrl);
                
                socket.onopen = () => {
                    logDebug('âœ… WebSocket connected to backend');
                    updateStatus(websocketStatus, 'Connected', 'connected');
                    
                    isRecording = true;
                    startButton.disabled = true;
                    stopButton.disabled = false;
                    
                    // Set up audio processing
                    audioContext = new AudioContext({ sampleRate: 16000 });
                    const source = audioContext.createMediaStreamSource(audioStream);
                    
                    // Create a processor to handle audio data
                    const processor = audioContext.createScriptProcessor(4096, 1, 1);
                    
                    processor.onaudioprocess = (event) => {
                        if (socket.readyState === WebSocket.OPEN) {
                            // Convert Float32Array to Int16Array
                            const inputData = event.inputBuffer.getChannelData(0);
                            const int16Data = convertFloat32ToInt16(inputData);
                            
                            // Send audio data through WebSocket (send ArrayBuffer)
                            socket.send(int16Data.buffer);
                        }
                    };
                    
                    source.connect(processor);
                    processor.connect(audioContext.destination);
                    
                    logDebug('ðŸŽ¤ Recording started - Speak into microphone');
                };
                
                socket.onmessage = (event) => {
                    try {
                        const data = JSON.parse(event.data);
                        logDebug(`Received: ${JSON.stringify(data)}`);
                        
                        if (data.type === 'transcript' && data.transcript) {
                            if (data.is_final) {
                                // Final transcript - add to final text
                                finalText.innerHTML += data.transcript + ' ';
                                interimText.textContent = '';
                                currentInterim = '';
                                logDebug(`âœ… Final: ${data.transcript}`);
                            } else {
                                // Interim transcript - show as gray text
                                currentInterim = data.transcript;
                                interimText.textContent = currentInterim;
                                logDebug(`â³ Interim: ${data.transcript}`);
                            }
                        }
                    } catch (error) {
                        logDebug('Error parsing WebSocket message: ' + error.message);
                    }
                };
                
                socket.onerror = (error) => {
                    logDebug('âŒ WebSocket error: ' + error.message);
                    updateStatus(websocketStatus, 'Error', 'disconnected');
                };
                
                socket.onclose = () => {
                    logDebug('WebSocket connection closed');
                    updateStatus(websocketStatus, 'Disconnected', 'disconnected');
                    if (isRecording) {
                        stopRecording();
                    }
                };
                
            } catch (error) {
                logDebug('âŒ Error starting recording: ' + error.message);
                updateStatus(microphoneStatus, 'Access denied', 'disconnected');
                alert('Error accessing microphone: ' + error.message);
            }
        }
        
        function stopRecording() {
            logDebug('Stopping recording...');
            
            if (socket) {
                socket.close();
            }
            
            if (audioStream) {
                audioStream.getTracks().forEach(track => track.stop());
            }
            
            if (audioContext) {
                audioContext.close();
            }
            
            isRecording = false;
            startButton.disabled = false;
            stopButton.disabled = true;
            updateStatus(microphoneStatus, 'Not active', 'disconnected');
            updateStatus(websocketStatus, 'Disconnected', 'disconnected');
            
            logDebug('Recording stopped');
            interimText.textContent = '';
        }
        
        function convertFloat32ToInt16(float32Array) {
            const int16Array = new Int16Array(float32Array.length);
            for (let i = 0; i < float32Array.length; i++) {
                // Convert from float32 (-1 to 1) to int16
                const s = Math.max(-1, Math.min(1, float32Array[i]));
                int16Array[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
            }
            return int16Array;
        }
        
        // Clean up on page unload
        window.addEventListener('beforeunload', () => {
            if (isRecording) {
                stopRecording();
            }
        });
    </script>
</body>
</html>